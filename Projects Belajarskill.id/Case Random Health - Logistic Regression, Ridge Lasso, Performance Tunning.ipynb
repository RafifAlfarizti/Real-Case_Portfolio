{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d89ff1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a71473f",
   "metadata": {},
   "source": [
    "# Setting DataFrame Random "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8d670e",
   "metadata": {},
   "source": [
    "Usia (Age)\n",
    "Variabel ini umumnya diukur dalam tahun.\n",
    "Rentang nilai optimal: Bervariasi tergantung studi, tetapi biasanya antara 0 dan 100 tahun.\n",
    "\n",
    "Jenis Kelamin (Gender)\n",
    "Variabel ini dapat berupa data kategorikal yang diubah menjadi variabel dummy (misalnya, 0 untuk laki-laki, 1 untuk perempuan).\n",
    "Rentang nilai optimal: 0 atau 1.\n",
    "\n",
    "Indeks Massa Tubuh (Body Mass Index - BMI)\n",
    "BMI adalah angka yang dihitung berdasarkan berat dan tinggi badan.\n",
    "Rentang nilai optimal: Biasanya antara 15 dan 40, tetapi bisa melampaui rentang ini dalam kasus obesitas ekstrem atau malnutrisi parah.\n",
    "\n",
    "Tekanan Darah (Blood Pressure)\n",
    "Variabel ini sering dibagi menjadi tekanan darah sistolik dan diastolik, diukur dalam mmHg.\n",
    "Rentang nilai optimal: Tekanan darah sistolik biasanya antara 90 dan 180 mmHg, tekanan darah diastolik antara 60 dan 120 mmHg. Variasi di luar rentang ini mungkin menunjukkan hipertensi atau hipotensi ekstrem.\n",
    "\n",
    "Kadar Kolesterol (Cholesterol Level)\n",
    "Kadar kolesterol diukur dalam miligram per desiliter (mg/dL).\n",
    "Rentang nilai optimal: Biasanya antara 100 dan 300 mg/dL, dengan batas aman untuk kolesterol total adalah kurang dari 200 mg/dL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e13ce8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usia</th>\n",
       "      <th>Jenis Kelamin</th>\n",
       "      <th>Indeks Massa Tubuh</th>\n",
       "      <th>Tekanan Sistolik</th>\n",
       "      <th>Tekanan Diastolik</th>\n",
       "      <th>Kadar Kolesterol</th>\n",
       "      <th>Status Merokok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>110</td>\n",
       "      <td>72</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>103</td>\n",
       "      <td>102</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>120</td>\n",
       "      <td>104</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>112</td>\n",
       "      <td>84</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>105</td>\n",
       "      <td>112</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>90</td>\n",
       "      <td>68</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>116</td>\n",
       "      <td>96</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>116</td>\n",
       "      <td>79</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>105</td>\n",
       "      <td>85</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>98</td>\n",
       "      <td>88</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Usia  Jenis Kelamin  Indeks Massa Tubuh  Tekanan Sistolik  \\\n",
       "0      38              1                  36               110   \n",
       "1      28              0                  30               103   \n",
       "2      14              0                  22               120   \n",
       "3      42              1                  18               112   \n",
       "4       7              0                  22               105   \n",
       "..    ...            ...                 ...               ...   \n",
       "495     4              0                  30                90   \n",
       "496    11              0                  18               116   \n",
       "497    15              1                  34               116   \n",
       "498    25              0                  19               105   \n",
       "499    25              0                  36                98   \n",
       "\n",
       "     Tekanan Diastolik  Kadar Kolesterol   Status Merokok  \n",
       "0                   72                 60               0  \n",
       "1                  102                114               0  \n",
       "2                  104                 94               0  \n",
       "3                   84                 65               1  \n",
       "4                  112                 96               0  \n",
       "..                 ...                ...             ...  \n",
       "495                 68                 75               0  \n",
       "496                 96                 66               0  \n",
       "497                 79                111               1  \n",
       "498                 85                 73               0  \n",
       "499                 88                 68               0  \n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate random data\n",
    "np.random.seed(42)\n",
    "\n",
    "usia = np.random.randint(0, 50, size=500)\n",
    "jk = np.random.randint(0, 2, size=500)\n",
    "bmi = np.random.randint(15, 41, size=500)\n",
    "sistol = np.random.randint(90, 121, size=500)\n",
    "diastol = np.random.randint(60, 120, size=500)\n",
    "kolestrol = np.random.randint(60, 120, size=500)\n",
    "smoke = np.random.randint(0, 2, size=500)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Usia': usia,\n",
    "    'Jenis Kelamin': jk,\n",
    "    'Indeks Massa Tubuh': bmi,\n",
    "    'Tekanan Sistolik': sistol,\n",
    "    'Tekanan Diastolik': diastol,\n",
    "    'Kadar Kolesterol ': kolestrol,\n",
    "    'Status Merokok': smoke,\n",
    "})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37e8323",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96a5c731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train Scaled:  [[0.3877551  0.28       0.56666667 0.15254237 0.89830508]\n",
      " [0.10204082 0.48       0.33333333 0.98305085 0.33898305]\n",
      " [0.87755102 0.8        0.56666667 0.69491525 0.71186441]\n",
      " ...\n",
      " [0.65306122 0.16       0.66666667 0.98305085 0.61016949]\n",
      " [0.85714286 0.72       0.76666667 0.94915254 0.08474576]\n",
      " [0.         0.12       0.16666667 0.52542373 0.50847458]]\n",
      "X Test Scaled:  [[0.10204082 0.84       0.93333333 0.49152542 0.81355932]\n",
      " [0.67346939 0.68       0.83333333 0.27118644 0.44067797]\n",
      " [0.44897959 0.         0.03333333 0.83050847 0.03389831]\n",
      " [0.06122449 0.72       0.6        0.55932203 0.03389831]\n",
      " [0.14285714 0.84       0.23333333 0.16949153 0.16949153]\n",
      " [0.51020408 1.         0.26666667 0.89830508 0.72881356]\n",
      " [0.34693878 0.72       0.63333333 0.52542373 0.96610169]\n",
      " [0.44897959 0.         0.         0.52542373 0.10169492]\n",
      " [0.06122449 0.88       0.7        0.52542373 0.11864407]\n",
      " [0.79591837 0.84       0.13333333 0.16949153 0.54237288]\n",
      " [0.20408163 0.08       0.         1.         0.81355932]\n",
      " [0.16326531 0.36       0.36666667 0.10169492 0.23728814]\n",
      " [1.         0.92       0.26666667 0.59322034 0.49152542]\n",
      " [0.40816327 0.96       0.1        0.28813559 0.88135593]\n",
      " [0.65306122 0.84       0.33333333 0.3220339  0.62711864]\n",
      " [0.42857143 0.8        0.43333333 0.08474576 0.55932203]\n",
      " [0.08163265 0.6        0.         0.13559322 0.25423729]\n",
      " [0.53061224 1.         0.73333333 0.22033898 0.83050847]\n",
      " [0.81632653 0.12       0.96666667 0.28813559 0.13559322]\n",
      " [0.46938776 0.24       0.63333333 0.49152542 0.91525424]\n",
      " [0.08163265 0.92       0.76666667 0.98305085 0.69491525]\n",
      " [0.93877551 0.52       0.6        0.3220339  0.49152542]\n",
      " [0.         0.         0.2        0.66101695 0.05084746]\n",
      " [0.87755102 0.84       0.1        0.23728814 0.08474576]\n",
      " [0.26530612 0.08       0.03333333 0.27118644 0.76271186]\n",
      " [0.73469388 0.36       0.5        0.6779661  0.        ]\n",
      " [0.30612245 0.76       0.86666667 0.3220339  0.86440678]\n",
      " [0.97959184 0.08       1.         0.16949153 0.76271186]\n",
      " [0.46938776 0.56       1.         0.23728814 0.20338983]\n",
      " [0.91836735 1.         0.53333333 0.88135593 0.38983051]\n",
      " [0.         0.08       0.4        0.61016949 0.3559322 ]\n",
      " [0.75510204 0.28       0.4        0.52542373 0.76271186]\n",
      " [0.87755102 0.6        0.26666667 0.06779661 0.52542373]\n",
      " [0.10204082 0.76       0.         0.11864407 0.72881356]\n",
      " [0.28571429 0.28       1.         0.74576271 0.57627119]\n",
      " [0.42857143 0.44       0.96666667 0.91525424 0.6440678 ]\n",
      " [0.24489796 0.76       0.83333333 0.37288136 0.25423729]\n",
      " [0.34693878 0.4        0.43333333 0.83050847 0.66101695]\n",
      " [0.02040816 0.2        0.6        0.38983051 0.88135593]\n",
      " [0.79591837 0.92       0.4        0.61016949 0.49152542]\n",
      " [0.46938776 0.32       0.7        0.01694915 0.01694915]\n",
      " [0.81632653 0.76       0.36666667 0.86440678 0.13559322]\n",
      " [0.73469388 0.         0.86666667 0.45762712 0.28813559]\n",
      " [0.         0.4        0.36666667 1.         0.74576271]\n",
      " [0.30612245 1.         0.63333333 0.18644068 0.62711864]\n",
      " [0.6122449  0.72       0.73333333 0.15254237 0.05084746]\n",
      " [0.7755102  0.84       0.66666667 0.20338983 0.        ]\n",
      " [0.46938776 1.         0.66666667 0.06779661 0.22033898]\n",
      " [0.14285714 0.4        0.56666667 0.91525424 0.3220339 ]\n",
      " [0.02040816 0.16       0.46666667 0.71186441 0.83050847]\n",
      " [0.87755102 0.48       0.83333333 0.44067797 0.18644068]\n",
      " [0.48979592 0.4        0.06666667 0.72881356 0.72881356]\n",
      " [0.53061224 0.6        0.66666667 0.44067797 0.10169492]\n",
      " [0.12244898 0.2        0.53333333 0.69491525 0.18644068]\n",
      " [0.53061224 0.88       0.13333333 0.22033898 1.        ]\n",
      " [0.87755102 1.         0.53333333 0.15254237 0.77966102]\n",
      " [0.51020408 0.12       0.13333333 0.03389831 0.11864407]\n",
      " [0.46938776 0.84       0.9        0.37288136 0.98305085]\n",
      " [0.81632653 0.64       0.46666667 0.3559322  0.30508475]\n",
      " [0.95918367 0.56       0.13333333 0.89830508 0.54237288]\n",
      " [0.91836735 0.4        0.9        0.01694915 0.03389831]\n",
      " [0.34693878 0.04       0.2        0.20338983 0.3559322 ]\n",
      " [0.95918367 0.36       0.46666667 0.74576271 0.10169492]\n",
      " [0.51020408 0.08       0.03333333 0.72881356 0.69491525]\n",
      " [0.28571429 0.96       0.33333333 0.         0.        ]\n",
      " [0.12244898 0.92       0.03333333 0.44067797 0.83050847]\n",
      " [0.30612245 0.64       0.33333333 0.15254237 0.37288136]\n",
      " [0.26530612 0.28       0.36666667 1.         0.        ]\n",
      " [0.10204082 0.52       0.7        0.18644068 0.10169492]\n",
      " [0.53061224 0.08       0.03333333 0.84745763 0.86440678]\n",
      " [0.06122449 0.36       0.46666667 0.84745763 0.13559322]\n",
      " [0.53061224 0.28       0.1        0.28813559 0.69491525]\n",
      " [0.95918367 0.76       0.73333333 0.91525424 0.42372881]\n",
      " [0.95918367 0.12       0.         0.52542373 0.30508475]\n",
      " [0.71428571 0.12       0.66666667 0.89830508 0.22033898]\n",
      " [0.69387755 0.76       0.4        0.25423729 0.33898305]\n",
      " [1.         0.24       0.36666667 0.62711864 0.15254237]\n",
      " [0.57142857 0.52       0.33333333 0.59322034 0.77966102]\n",
      " [0.59183673 0.12       0.9        0.25423729 0.6779661 ]\n",
      " [0.2244898  0.04       0.13333333 0.11864407 0.37288136]\n",
      " [0.63265306 0.2        0.63333333 0.23728814 0.13559322]\n",
      " [0.44897959 0.36       0.66666667 0.93220339 0.25423729]\n",
      " [0.7755102  0.88       0.93333333 0.61016949 0.61016949]\n",
      " [0.89795918 0.         0.53333333 0.88135593 0.23728814]\n",
      " [0.26530612 0.76       0.76666667 0.20338983 0.01694915]\n",
      " [0.51020408 0.96       0.8        0.59322034 0.01694915]\n",
      " [0.20408163 0.2        0.2        0.03389831 0.76271186]\n",
      " [0.         0.64       0.06666667 0.01694915 0.11864407]\n",
      " [0.34693878 0.48       0.93333333 1.         0.10169492]\n",
      " [0.97959184 0.56       0.73333333 0.72881356 0.44067797]\n",
      " [0.04081633 0.56       0.63333333 0.88135593 0.01694915]\n",
      " [0.48979592 0.         0.53333333 0.45762712 0.3559322 ]\n",
      " [0.69387755 0.4        0.13333333 0.33898305 1.        ]\n",
      " [0.3877551  0.28       0.8        0.84745763 0.33898305]\n",
      " [0.97959184 0.24       0.13333333 0.08474576 0.94915254]\n",
      " [0.93877551 0.12       0.         0.6779661  0.66101695]\n",
      " [0.89795918 0.24       0.16666667 0.22033898 0.06779661]\n",
      " [0.71428571 0.2        0.4        0.3559322  0.40677966]\n",
      " [0.14285714 0.64       0.9        0.57627119 0.11864407]\n",
      " [0.04081633 0.16       0.6        0.94915254 0.88135593]]\n"
     ]
    }
   ],
   "source": [
    "# Pisahkan variabel dependen (target) dan independen (fitur)\n",
    "X = data.drop(['Status Merokok','Jenis Kelamin'], axis=1)\n",
    "y = data['Status Merokok']\n",
    "\n",
    "# Pisahkan data menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisasi data menggunakan StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"X Train Scaled: \", X_train_scaled)\n",
    "print(\"X Test Scaled: \", X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a255487",
   "metadata": {},
   "source": [
    "# Pemodelan Regresi Logistik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7812bf98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buat objek model Regresi Logistik\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Latih model dengan data latih\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e78b31ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10204082 0.84       0.93333333 0.49152542 0.81355932]\n",
      " [0.67346939 0.68       0.83333333 0.27118644 0.44067797]\n",
      " [0.44897959 0.         0.03333333 0.83050847 0.03389831]\n",
      " [0.06122449 0.72       0.6        0.55932203 0.03389831]\n",
      " [0.14285714 0.84       0.23333333 0.16949153 0.16949153]\n",
      " [0.51020408 1.         0.26666667 0.89830508 0.72881356]\n",
      " [0.34693878 0.72       0.63333333 0.52542373 0.96610169]\n",
      " [0.44897959 0.         0.         0.52542373 0.10169492]\n",
      " [0.06122449 0.88       0.7        0.52542373 0.11864407]\n",
      " [0.79591837 0.84       0.13333333 0.16949153 0.54237288]\n",
      " [0.20408163 0.08       0.         1.         0.81355932]\n",
      " [0.16326531 0.36       0.36666667 0.10169492 0.23728814]\n",
      " [1.         0.92       0.26666667 0.59322034 0.49152542]\n",
      " [0.40816327 0.96       0.1        0.28813559 0.88135593]\n",
      " [0.65306122 0.84       0.33333333 0.3220339  0.62711864]\n",
      " [0.42857143 0.8        0.43333333 0.08474576 0.55932203]\n",
      " [0.08163265 0.6        0.         0.13559322 0.25423729]\n",
      " [0.53061224 1.         0.73333333 0.22033898 0.83050847]\n",
      " [0.81632653 0.12       0.96666667 0.28813559 0.13559322]\n",
      " [0.46938776 0.24       0.63333333 0.49152542 0.91525424]\n",
      " [0.08163265 0.92       0.76666667 0.98305085 0.69491525]\n",
      " [0.93877551 0.52       0.6        0.3220339  0.49152542]\n",
      " [0.         0.         0.2        0.66101695 0.05084746]\n",
      " [0.87755102 0.84       0.1        0.23728814 0.08474576]\n",
      " [0.26530612 0.08       0.03333333 0.27118644 0.76271186]\n",
      " [0.73469388 0.36       0.5        0.6779661  0.        ]\n",
      " [0.30612245 0.76       0.86666667 0.3220339  0.86440678]\n",
      " [0.97959184 0.08       1.         0.16949153 0.76271186]\n",
      " [0.46938776 0.56       1.         0.23728814 0.20338983]\n",
      " [0.91836735 1.         0.53333333 0.88135593 0.38983051]\n",
      " [0.         0.08       0.4        0.61016949 0.3559322 ]\n",
      " [0.75510204 0.28       0.4        0.52542373 0.76271186]\n",
      " [0.87755102 0.6        0.26666667 0.06779661 0.52542373]\n",
      " [0.10204082 0.76       0.         0.11864407 0.72881356]\n",
      " [0.28571429 0.28       1.         0.74576271 0.57627119]\n",
      " [0.42857143 0.44       0.96666667 0.91525424 0.6440678 ]\n",
      " [0.24489796 0.76       0.83333333 0.37288136 0.25423729]\n",
      " [0.34693878 0.4        0.43333333 0.83050847 0.66101695]\n",
      " [0.02040816 0.2        0.6        0.38983051 0.88135593]\n",
      " [0.79591837 0.92       0.4        0.61016949 0.49152542]\n",
      " [0.46938776 0.32       0.7        0.01694915 0.01694915]\n",
      " [0.81632653 0.76       0.36666667 0.86440678 0.13559322]\n",
      " [0.73469388 0.         0.86666667 0.45762712 0.28813559]\n",
      " [0.         0.4        0.36666667 1.         0.74576271]\n",
      " [0.30612245 1.         0.63333333 0.18644068 0.62711864]\n",
      " [0.6122449  0.72       0.73333333 0.15254237 0.05084746]\n",
      " [0.7755102  0.84       0.66666667 0.20338983 0.        ]\n",
      " [0.46938776 1.         0.66666667 0.06779661 0.22033898]\n",
      " [0.14285714 0.4        0.56666667 0.91525424 0.3220339 ]\n",
      " [0.02040816 0.16       0.46666667 0.71186441 0.83050847]\n",
      " [0.87755102 0.48       0.83333333 0.44067797 0.18644068]\n",
      " [0.48979592 0.4        0.06666667 0.72881356 0.72881356]\n",
      " [0.53061224 0.6        0.66666667 0.44067797 0.10169492]\n",
      " [0.12244898 0.2        0.53333333 0.69491525 0.18644068]\n",
      " [0.53061224 0.88       0.13333333 0.22033898 1.        ]\n",
      " [0.87755102 1.         0.53333333 0.15254237 0.77966102]\n",
      " [0.51020408 0.12       0.13333333 0.03389831 0.11864407]\n",
      " [0.46938776 0.84       0.9        0.37288136 0.98305085]\n",
      " [0.81632653 0.64       0.46666667 0.3559322  0.30508475]\n",
      " [0.95918367 0.56       0.13333333 0.89830508 0.54237288]\n",
      " [0.91836735 0.4        0.9        0.01694915 0.03389831]\n",
      " [0.34693878 0.04       0.2        0.20338983 0.3559322 ]\n",
      " [0.95918367 0.36       0.46666667 0.74576271 0.10169492]\n",
      " [0.51020408 0.08       0.03333333 0.72881356 0.69491525]\n",
      " [0.28571429 0.96       0.33333333 0.         0.        ]\n",
      " [0.12244898 0.92       0.03333333 0.44067797 0.83050847]\n",
      " [0.30612245 0.64       0.33333333 0.15254237 0.37288136]\n",
      " [0.26530612 0.28       0.36666667 1.         0.        ]\n",
      " [0.10204082 0.52       0.7        0.18644068 0.10169492]\n",
      " [0.53061224 0.08       0.03333333 0.84745763 0.86440678]\n",
      " [0.06122449 0.36       0.46666667 0.84745763 0.13559322]\n",
      " [0.53061224 0.28       0.1        0.28813559 0.69491525]\n",
      " [0.95918367 0.76       0.73333333 0.91525424 0.42372881]\n",
      " [0.95918367 0.12       0.         0.52542373 0.30508475]\n",
      " [0.71428571 0.12       0.66666667 0.89830508 0.22033898]\n",
      " [0.69387755 0.76       0.4        0.25423729 0.33898305]\n",
      " [1.         0.24       0.36666667 0.62711864 0.15254237]\n",
      " [0.57142857 0.52       0.33333333 0.59322034 0.77966102]\n",
      " [0.59183673 0.12       0.9        0.25423729 0.6779661 ]\n",
      " [0.2244898  0.04       0.13333333 0.11864407 0.37288136]\n",
      " [0.63265306 0.2        0.63333333 0.23728814 0.13559322]\n",
      " [0.44897959 0.36       0.66666667 0.93220339 0.25423729]\n",
      " [0.7755102  0.88       0.93333333 0.61016949 0.61016949]\n",
      " [0.89795918 0.         0.53333333 0.88135593 0.23728814]\n",
      " [0.26530612 0.76       0.76666667 0.20338983 0.01694915]\n",
      " [0.51020408 0.96       0.8        0.59322034 0.01694915]\n",
      " [0.20408163 0.2        0.2        0.03389831 0.76271186]\n",
      " [0.         0.64       0.06666667 0.01694915 0.11864407]\n",
      " [0.34693878 0.48       0.93333333 1.         0.10169492]\n",
      " [0.97959184 0.56       0.73333333 0.72881356 0.44067797]\n",
      " [0.04081633 0.56       0.63333333 0.88135593 0.01694915]\n",
      " [0.48979592 0.         0.53333333 0.45762712 0.3559322 ]\n",
      " [0.69387755 0.4        0.13333333 0.33898305 1.        ]\n",
      " [0.3877551  0.28       0.8        0.84745763 0.33898305]\n",
      " [0.97959184 0.24       0.13333333 0.08474576 0.94915254]\n",
      " [0.93877551 0.12       0.         0.6779661  0.66101695]\n",
      " [0.89795918 0.24       0.16666667 0.22033898 0.06779661]\n",
      " [0.71428571 0.2        0.4        0.3559322  0.40677966]\n",
      " [0.14285714 0.64       0.9        0.57627119 0.11864407]\n",
      " [0.04081633 0.16       0.6        0.94915254 0.88135593]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Contoh Feature Selection dengan Univariate Feature Selection\n",
    "selector = SelectKBest(score_func=chi2, k=5)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "print(X_test_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65313fc",
   "metadata": {},
   "source": [
    "# Regularization dengan Regresi Lasso dan Rigid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a90bac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.01)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contoh Regularization dengan L1 Regularization (Lasso)\n",
    "lasso_model = LogisticRegression(penalty='l1', solver='liblinear', C=0.01)\n",
    "lasso_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Contoh Regularization dengan L2 Regularization (Ridge)\n",
    "ridge_model = LogisticRegression(penalty='l2', C=0.01)\n",
    "ridge_model.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11a8a27",
   "metadata": {},
   "source": [
    "solver='liblinear'\n",
    "liblinear adalah solver yang digunakan untuk mengoptimalkan model. Solver ini mendukung regularisasi L1 dan L2, dan lebih cocok untuk dataset yang lebih kecil atau masalah dengan lebih sedikit fitur.\n",
    "\n",
    "C=0.01\n",
    "Parameter C adalah kebalikan dari kekuatan regularisasi. Nilai yang lebih kecil dari C berarti regularisasi yang lebih kuat, sedangkan nilai yang lebih besar berarti regularisasi yang lebih lemah. Dengan C=0.01, model akan memiliki regularisasi yang cukup kuat, mempengaruhi sejauh mana koefisien model dapat \"ditekan\" oleh regularisasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e2c06e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.]\n",
      "[-0.01112643  0.02613495  0.02272398  0.02345801 -0.03043821]\n"
     ]
    }
   ],
   "source": [
    "print(lasso_model.coef_[0])\n",
    "print(ridge_model.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc29ec97",
   "metadata": {},
   "source": [
    "Pada regresi lasso, seluruh koefisien untuk model Lasso adalah nol. Ini bisa berarti:\n",
    "\n",
    "1. Model Lasso telah melakukan regularisasi yang sangat kuat, sehingga semua koefisien ditekan menjadi nol.\n",
    "2. Tidak ada fitur yang dianggap cukup penting untuk digunakan dalam model setelah penerapan regularisasi L1 yang kuat.\n",
    "3. Ketika semua koefisien adalah nol, model tidak memiliki informasi untuk membedakan antara kelas-kelas, yang dapat menjadi indikasi over-regularization atau bahwa data dan fitur yang digunakan tidak relevan atau tidak cukup beragam.\n",
    "\n",
    "Regresi rigid cenderung meratakan koefisien dan mencegahnya menjadi sangat besar, namun jarang menghasilkan koefisien nol seperti L1. Dalam kasus ini, model Ridge memiliki koefisien dengan berbagai nilai, termasuk positif dan negatif. Ini menunjukkan:\n",
    "1. Regularisasi L2 tidak menekan koefisien hingga nol, tetapi mengurangi besarnya koefisien sehingga tetap stabil dan mencegah overfitting.\n",
    "2. Setiap nilai koefisien menunjukkan seberapa besar pengaruh masing-masing fitur terhadap prediksi. Nilai positif menunjukkan bahwa peningkatan fitur akan meningkatkan peluang menjadi satu kelas, sementara nilai negatif menunjukkan sebaliknya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1c007",
   "metadata": {},
   "source": [
    "# Prediksi dengan Regresi Lasso dan Rigid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a9a1412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilai prediksi Ridge:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alfar\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:402: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Membuat prediksi\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "\n",
    "# Menampilkan nilai prediksi Ridge\n",
    "print(\"Nilai prediksi Ridge:\")\n",
    "print(y_pred_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99ec4839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilai prediksi Lasso:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alfar\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:402: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Membuat prediksi\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "# Menampilkan nilai prediksi lasso\n",
    "print(\"Nilai prediksi Lasso:\")\n",
    "print(y_pred_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baa7454",
   "metadata": {},
   "source": [
    "# Grid Search untuk mencari parameter terbaik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053e3ea6",
   "metadata": {},
   "source": [
    "Parameter yang digunakan:\n",
    "1. penalty: ['l2'] - Regularisasi yang dicoba adalah regularisasi L2 (regresi rigid).\n",
    "2. C: [0.01, 0.1, 1.0, 10.0] - Nilai C adalah kebalikan dari kekuatan regularisasi; nilai yang lebih kecil berarti regularisasi yang lebih kuat, dan nilai yang lebih besar berarti regularisasi yang lebih lemah.\n",
    "3. fit_intercept: [True, False] - Apakah model harus mencakup intercept (bias) atau tidak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9b8b00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.01, 'fit_intercept': False, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define the list of parameter values to be tried in the Grid Search\n",
    "param_grid = {'penalty': ['l2'], 'C': [0.01, 0.1, 1.0, 10.0], 'fit_intercept': [True, False]}\n",
    "\n",
    "# Perform Grid Search with K-Fold Cross Validation (k=5)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', error_score='raise')\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e30245d",
   "metadata": {},
   "source": [
    "Output ini memberi tahu kita bahwa, berdasarkan pengaturan Grid Search dan data yang digunakan, model dengan regularisasi L2, nilai C 0.01 (regularisasi kuat), dan tanpa intercept memberikan kinerja terbaik. Dengan kata lain, model dengan regularisasi yang kuat dan tanpa intercept lebih cocok untuk dataset dan tugas yang Anda miliki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e752ecac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
